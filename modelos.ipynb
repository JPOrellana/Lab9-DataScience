{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science - Laboratorio 9\n",
    "## Visualizaciones interactivas y dashboards\n",
    "### Modelos LSTM\n",
    "---\n",
    "**Integrantes**\n",
    "- Diego Alberto Leiva\n",
    "- José Pablo Orellana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulacion de Datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sistema\n",
    "import os\n",
    "\n",
    "# Utilidades\n",
    "import random\n",
    "\n",
    "# Preprocesamiento\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# PyTorch CUDA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de Datos Limpios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer los archivos de una carpeta y almacenarlos como dataframes\n",
    "consumos = pd.read_csv('data/consumos_clean.csv', sep=';', encoding='utf-8')\n",
    "importaciones = pd.read_csv('data/importaciones_clean.csv', sep=';', encoding='utf-8')\n",
    "precios = pd.read_csv('data/precios_clean.csv', sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuracion de PyTorch con CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se verifica si el sistema tiene capacidad de CUDA o no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA AVAILABLE\n",
      "Using: NVIDIA GeForce RTX 3070 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Configurar la semilla para la reproducibilidad\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA AVAILABLE\")\n",
    "\n",
    "    print(f\"Using: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "    # Configurar el generador de números aleatorios de CUDA\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # Multi-GPU.\n",
    "\n",
    "    # Configurar PyTorch a determinista\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "else:\n",
    "    # Si no hay GPU disponible, usar la CPU\n",
    "    print(\"CUDA NOT AVAILABLE\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquitectura de una LSTM con PyTorch CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model():\n",
    "    \"\"\"\n",
    "    Clase para entrenar un modelo LSTM para predecir series temporales y actualizar el dataframe con las predicciones.\n",
    "\n",
    "    Args:\n",
    "        hidden_layers (int): Número de capas ocultas.\n",
    "        num_layers (int): Número de capas LSTM.\n",
    "        lookback (int): Número de pasos de tiempo hacia atrás.\n",
    "        n_epochs (int): Número de épocas.\n",
    "        test_size (int): Tamaño del conjunto de prueba.\n",
    "        dataframe (pandas.DataFrame): Dataframe de entrada.\n",
    "        target_column (str): Columna objetivo.\n",
    "\n",
    "    Attributes:\n",
    "        hidden_layers (int): Número de capas ocultas.\n",
    "        num_layers (int): Número de capas LSTM.\n",
    "        lookback (int): Número de pasos de tiempo hacia atrás.\n",
    "        n_epochs (int): Número de épocas.\n",
    "        test_size (int): Tamaño del conjunto de prueba.\n",
    "        dataframe (pandas.DataFrame): Dataframe de entrada.\n",
    "        target_column (str): Columna objetivo.\n",
    "        model (torch.nn.Module): Modelo LSTM.\n",
    "        loss_fn (torch.nn.Module): Función de pérdida.\n",
    "        optimizer (torch.optim.Optimizer): Optimizador.\n",
    "        train_size (int): Tamaño del conjunto de entrenamiento.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_layers, num_layers, lookback, n_epochs, test_size, dataframe, target_column):\n",
    "        \n",
    "        # Parámetros fijos\n",
    "        self.input_size = 1                    # Fijo, tamaño de entrada\n",
    "        self.output_size = 1                   # Fijo, tamaño de salida\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Dispositivo fijo\n",
    "        \n",
    "        # Inicializar otros hiperparámetros\n",
    "        self.hidden_layers = hidden_layers     # Número de capas ocultas\n",
    "        self.num_layers = num_layers           # Número de capas LSTM\n",
    "        self.lookback = lookback               # Número de pasos de tiempo hacia atrás\n",
    "        self.n_epochs = n_epochs               # Número de épocas\n",
    "        self.test_size = test_size             # Tamaño del conjunto de prueba\n",
    "        self.dataframe = dataframe             # Dataframe de entrada\n",
    "        self.target_column = target_column     # Columna objetivo\n",
    "\n",
    "        # Crear el modelo LSTM \n",
    "        self.model = self.build_lstm_model()\n",
    "\n",
    "        # Definir la función de pérdida y el optimizador\n",
    "        self.loss_fn = nn.MSELoss().to(self.device)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "\n",
    "        # Entrenar el modelo y actualizar el dataframe\n",
    "        self.train_preds, self.test_preds = self.train_model(dataframe, target_column)\n",
    "        self.updated_data = self.add_preds(self.dataframe, target_column, self.train_preds, self.test_preds)\n",
    "\n",
    "    def build_lstm_model(self):\n",
    "        \"\"\"\n",
    "        Función para construir el modelo LSTM.\n",
    "\n",
    "        Returns:\n",
    "            model (torch.nn.Module): El modelo LSTM.\n",
    "        \"\"\"\n",
    "        class LSTM(nn.Module):\n",
    "            def __init__(self, input_size, hidden_layers, output_size, num_layers):\n",
    "                super(LSTM, self).__init__()\n",
    "\n",
    "                # Definir la capa LSTM\n",
    "                self.lstm = nn.LSTM(input_size=input_size, \n",
    "                                    hidden_size=hidden_layers, \n",
    "                                    num_layers=num_layers, \n",
    "                                    batch_first=True)\n",
    "\n",
    "                # Definir la capa de salida\n",
    "                self.linear = nn.Linear(hidden_layers, output_size)\n",
    "\n",
    "                # Capa de activación ReLU\n",
    "                self.relu = nn.ReLU()\n",
    "                \n",
    "            def forward(self, x):\n",
    "                # Inicializar hidden states\n",
    "                h0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n",
    "                c0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n",
    "\n",
    "                # Forward pass a través de LSTM\n",
    "                out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "                # Aplicar la capa de activación\n",
    "                out = self.relu(out)\n",
    "\n",
    "                # Solo el último hidden state\n",
    "                out = self.linear(out[:, -1, :])\n",
    "                \n",
    "                # Devolver la predicción\n",
    "                return out\n",
    "\n",
    "        # Crear el modelo LSTM con los hiperparámetros definidos\n",
    "        return LSTM(self.input_size, self.hidden_layers, self.output_size, self.num_layers).to(self.device)\n",
    "\n",
    "\n",
    "    def prepare_data(self, dataset):\n",
    "        \"\"\"\n",
    "        Función para crear el dataset de entrenamiento.\n",
    "\n",
    "        Args:\n",
    "            dataset (numpy.array): El dataset de entrada.\n",
    "\n",
    "        Returns:\n",
    "            X (torch.Tensor): El tensor de features.\n",
    "            y (torch.Tensor): El tensor de target.\n",
    "        \"\"\"\n",
    "        X, y = [], []\n",
    "        for i in range(len(dataset) - self.lookback):\n",
    "            X.append(dataset[i:i + self.lookback])\n",
    "            y.append(dataset[i + self.lookback])\n",
    "\n",
    "        # Convertir listas a numpy arrays y luego a tensores\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        # Retornar tensores\n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    def train_model(self, dataframe, variable):\n",
    "        \"\"\"\n",
    "        Función para entrenar el modelo LSTM.\n",
    "\n",
    "        Args:\n",
    "            dataframe (pandas.DataFrame): El dataframe de entrada.\n",
    "\n",
    "        Returns:\n",
    "            pred_train (numpy.array): Predicciones sobre el conjunto de entrenamiento.\n",
    "            pred_test (numpy.array): Predicciones sobre el conjunto de prueba.\n",
    "        \"\"\"\n",
    "        # Preparar los datos\n",
    "        df = dataframe.copy()\n",
    "        timeseries = df[[variable]].values.astype(float)\n",
    "\n",
    "        # Normalizar los datos\n",
    "        scaler = StandardScaler()\n",
    "        timeseries = scaler.fit_transform(timeseries)\n",
    "\n",
    "        # Dividir en entrenamiento y prueba\n",
    "        self.train_size = len(timeseries) - self.test_size\n",
    "        train_data = timeseries[:self.train_size]\n",
    "        test_data = timeseries[self.train_size:]\n",
    "\n",
    "        # Crear datasets\n",
    "        X_train, y_train = self.prepare_data(train_data)\n",
    "        X_test, y_test = self.prepare_data(test_data)\n",
    "\n",
    "        # Mover los tensores al dispositivo\n",
    "        X_train, y_train = X_train.to(self.device), y_train.to(self.device)\n",
    "        X_test, y_test = X_test.to(self.device), y_test.to(self.device)\n",
    "\n",
    "        # Crear DataLoader para entrenamiento\n",
    "        loader = data.DataLoader(data.TensorDataset(X_train, y_train), batch_size=16, shuffle=False)\n",
    "\n",
    "        # Entrenar el modelo\n",
    "        for epoch in range(self.n_epochs):\n",
    "            self.model.train()\n",
    "            for X_batch, y_batch in loader:\n",
    "                X_batch, y_batch = X_batch.to(self.device), y_batch.to(self.device)\n",
    "\n",
    "                # Predicción\n",
    "                y_pred = self.model(X_batch)\n",
    "\n",
    "                # Calcular pérdida\n",
    "                loss = self.loss_fn(y_pred, y_batch)\n",
    "\n",
    "                # Backpropagation y optimización\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "        # Predicciones sobre el conjunto de entrenamiento y prueba\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred_train = self.model(X_train).cpu().numpy()\n",
    "            pred_test = self.model(X_test).cpu().numpy()\n",
    "\n",
    "        # Desnormalizar las predicciones \n",
    "        pred_train = scaler.inverse_transform(pred_train)\n",
    "        pred_test = scaler.inverse_transform(pred_test)\n",
    "        \n",
    "        # Retornar predicciones\n",
    "        return pred_train, pred_test\n",
    "\n",
    "    def add_preds(self, df, target_column, train_preds, test_preds):\n",
    "        \"\"\"\n",
    "        Agrega columnas de predicciones de entrenamiento y prueba al dataframe base tomando en cuenta el lookback.\n",
    "\n",
    "        Args:\n",
    "            df (pandas.DataFrame): Dataframe original.\n",
    "            target_column (str): Columna objetivo para las predicciones.\n",
    "            train_preds (numpy.array): Predicciones del conjunto de entrenamiento.\n",
    "            test_preds (numpy.array): Predicciones del conjunto de prueba.\n",
    "\n",
    "        Returns:\n",
    "            df (pandas.DataFrame): Dataframe actualizado con las predicciones.\n",
    "        \"\"\"\n",
    "        col_pred_train = f'pred_train_{target_column}'\n",
    "        col_pred_test = f'pred_test_{target_column}'\n",
    "\n",
    "        # Agregar columna de predicciones de entrenamiento con NaN en las primeras posiciones (lookback)\n",
    "        df[col_pred_train] = np.nan\n",
    "        df.loc[self.lookback:self.lookback + len(train_preds) - 1, col_pred_train] = train_preds.flatten()\n",
    "\n",
    "        # Agregar columna de predicciones de prueba, comenzando después de predicciones de entrenamiento + 2 * lookback\n",
    "        start_test = len(train_preds) + 2 * self.lookback\n",
    "        df[col_pred_test] = np.nan\n",
    "        df.loc[start_test:start_test + len(test_preds) - 1, col_pred_test] = test_preds.flatten()\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener predicciones de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consumos de Combustible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gasolina Superior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_consumo_super = LSTM_Model(\n",
    "    hidden_layers=55,\n",
    "    num_layers=1,\n",
    "    lookback=3,\n",
    "    n_epochs=100,\n",
    "    test_size=36,\n",
    "    dataframe=consumos,\n",
    "    target_column=\"Gasolina Superior\"\n",
    ")\n",
    "consumos = lstm_consumo_super.updated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA**: El número de predicciones que faltan (valores **NaN**) se debe a que el modelo LSTM utiliza ventanas de tiempo (definidas por `lookback`) para hacer las predicciones, lo que implica que para cada conjunto de datos (entrenamiento y prueba), el número total de predicciones será menor que el total de registros en el conjunto original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Gasolina Regular</th>\n",
       "      <th>Gasolina Superior</th>\n",
       "      <th>Diesel</th>\n",
       "      <th>pred_train_Gasolina Superior</th>\n",
       "      <th>pred_test_Gasolina Superior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>202645.20</td>\n",
       "      <td>308156.82</td>\n",
       "      <td>634667.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>205530.96</td>\n",
       "      <td>307766.31</td>\n",
       "      <td>642380.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>229499.56</td>\n",
       "      <td>331910.29</td>\n",
       "      <td>699807.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-04-01</td>\n",
       "      <td>210680.40</td>\n",
       "      <td>315648.08</td>\n",
       "      <td>586803.98</td>\n",
       "      <td>330589.46875</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-01</td>\n",
       "      <td>208164.34</td>\n",
       "      <td>319667.97</td>\n",
       "      <td>656948.20</td>\n",
       "      <td>330105.53125</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Fecha  Gasolina Regular  Gasolina Superior     Diesel  \\\n",
       "0  2000-01-01         202645.20          308156.82  634667.06   \n",
       "1  2000-02-01         205530.96          307766.31  642380.66   \n",
       "2  2000-03-01         229499.56          331910.29  699807.25   \n",
       "3  2000-04-01         210680.40          315648.08  586803.98   \n",
       "4  2000-05-01         208164.34          319667.97  656948.20   \n",
       "\n",
       "   pred_train_Gasolina Superior  pred_test_Gasolina Superior  \n",
       "0                           NaN                          NaN  \n",
       "1                           NaN                          NaN  \n",
       "2                           NaN                          NaN  \n",
       "3                  330589.46875                          NaN  \n",
       "4                  330105.53125                          NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Gasolina Regular</th>\n",
       "      <th>Gasolina Superior</th>\n",
       "      <th>Diesel</th>\n",
       "      <th>pred_train_Gasolina Superior</th>\n",
       "      <th>pred_test_Gasolina Superior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>830708.13</td>\n",
       "      <td>658083.66</td>\n",
       "      <td>1359012.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>642059.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>818740.16</td>\n",
       "      <td>654059.60</td>\n",
       "      <td>1340174.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>643978.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>870771.70</td>\n",
       "      <td>671997.05</td>\n",
       "      <td>1393324.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>637729.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>847353.15</td>\n",
       "      <td>633520.57</td>\n",
       "      <td>1428143.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>640871.1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>894533.14</td>\n",
       "      <td>692427.94</td>\n",
       "      <td>1401052.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>630325.6250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Fecha  Gasolina Regular  Gasolina Superior      Diesel  \\\n",
       "288  2024-01-01         830708.13          658083.66  1359012.49   \n",
       "289  2024-02-01         818740.16          654059.60  1340174.42   \n",
       "290  2024-03-01         870771.70          671997.05  1393324.52   \n",
       "291  2024-04-01         847353.15          633520.57  1428143.44   \n",
       "292  2024-05-01         894533.14          692427.94  1401052.37   \n",
       "\n",
       "     pred_train_Gasolina Superior  pred_test_Gasolina Superior  \n",
       "288                           NaN                  642059.3125  \n",
       "289                           NaN                  643978.2500  \n",
       "290                           NaN                  637729.8125  \n",
       "291                           NaN                  640871.1875  \n",
       "292                           NaN                  630325.6250  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumos.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gasolina Regular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Diesel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSci_L9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
